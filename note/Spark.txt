1、Spark定义
基于内存的快速、通用、可拓展的大数据分析计算引擎
迭代式数据开发，多个作业之间通信是基于内存，而Hadoop的MR是基于磁盘
概述：
A运行速度快：
内存计算、循环数据流
B有向无环图DAG执行引擎  进行流水线优化
C运行模式多样：独立的集群模式

2、核心模块
上层：
SQL:操作结构化数据，SQL查询
Streaming 对实时数据 流式计算
MLlib 机器学习
GraphX  图计算的框架和算法图，图算法
底层：
Spark Core 核心

3、代表性大数据技术Flink和Beam
Spark：基于批处理
Flink：基于连续流模型（优势流计算，性能稍好于spark）
Beam谷歌开发的统一编程接口，可翻译成其他各种引擎运行

4、Spark的设计和运行原理
核心数据抽象：RDD 弹性分布式数据集，分布式内存，可保存在多台机器内存上，动态分区，分区可大可小，可多可少
DAG：反应RDD之间的依赖关系，RDD一次次操作，形成有向无环图
Executor:运行在工作节点的进程，其中有很多进程，执行相关任务
Applocation:应用，用户写的应用程序
Task任务：运行在Executor线程上的工作单元
Job作业：一个作业包含多个RDD及作用于RDD的操作
Stage：作业的基本调度单位，一个作业分为阶段，一个阶段有多个任务
Driver 申请-> Manager 启动-> WorkNode [Executor[Task] ]

5、Spark运行基本流程
构建基本运行环境，构建Driver节点，生成SparkContext对象，【指挥官】，Sparkcontext申请资源，Executor启动进程、线程，根据DAG图，DAG Scheduler将其解析成不同Stage，每个阶段若干任务，线程工作节点申请任务，Task Scheduler将任务分发给工作节点，遵循计算向数据靠拢原则

6、RDD运行原理
背景：迭代计算，读取和储存需要反复序列化和反序列化开销
RDD为了避免这些，提供了抽象的数据结构，将复杂业务逻辑转化为RDD，不同的RDD转换之间就形成了DAG，再优化DAG
RDD就是分布式对象的集合，本职是只读的分区对象集合，分布式并行处理，RDD提供高度受限的共享内存模型，不能修改，只能通过生成新的RDD完成数据修改的目的

RDD操作：
支持粗粒度：一次对所有数据修改，整个RDD全集：动作类型操作、转换类型操作【丰富的转换类型，共同构建复杂逻辑】
不支持细粒度：单条数据修改：【因此不适爬虫】

RDD典型执行过程：
input->创建->转换[A]->转换[B]->动作
惰性机制：转换只记录轨迹，意向，并不会真发生计算，只有遇到动作类型，才真正执行从头到尾计算。

RDD特性
高效的容错性
现有容错机制：复制备份【开销大】
Spark：天然的容错机制  原因：1、DAG就是血缘关系图，可以寻亲，任何一个RDD丢失，都可以重新计算得到，
高效：中间结果持久化在内存，RDD.catch()，避免序列反序列化

RDD运行原理
应用 到 作业 到 不同阶段 到 任务集合

RDD的依赖关系
宽依赖：发生Shuffle操作     一个父对应多个子
窄依赖：没有Shuffle           一个父对应一个子  两个父对应一个子
Shuffle：交叉分发数据，

阶段划分依据：是宽依赖  还是 窄依赖

宽依赖划分多个阶段，窄依赖不用，原因：优化原理fork/join
窄依赖可以进行流水优化，宽依赖不行
fork分支join合并，实际过程不断fork/join
只要发生Shuffle一定会发生写磁盘，因此无法流水作业

DAG反向解析
窄依赖，则不断添加，流水作业
宽依赖，则划分阶段，不同阶段之间发生等待

7、Spark部署方式  单机/集群
集群部署模式：
Standalone：    Spark自带资源调度，效率不高
Mesos：           血缘关系，资源调度最高
YARN：            业界最多
概念：
Spark和Hadoop并不对等，而是与hadoop中MapReaduce对等，
Spark逐渐取代MapReaduce，Spark计算框架，Hadoop的HDFS和Hbase
仍是不可取代的存储框架

8、安装Spark
首先，构建基础环境，开发在Linux基础之上，存储需要Hadoop，Java环境
Spark版本与Java有对应要求，因为Spark底层编译成Java字节码执行
Spark2.4.0  JAVA 8以上  Hadoop 2.7.1
